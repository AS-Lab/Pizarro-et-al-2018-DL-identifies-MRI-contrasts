"""
===============================================
Load and test Convolutional Neural Network
===============================================

We developed two sequential neural networks to identify the brain MRI contrast.  The first network was a convolutional neural network that inferred the modality on a sagittal slice.  The second network combined the result generated by the first nerwork to infer the modality on the entire volume.  

This script was used to test the entire DL algortihm. We used the output generated by the convolutional neural network to test the second network, DNN.  The model architecture was loaded from .json string f saved using modality.save_NNarch_toJson.py.  The dataset was previously divided into three sets: training, validation, and testing.  The training and validation sets were used while training the algorithm.  The testing set was kept separate from the training and used in this script to test the model after training completed. 

The MRI volmes in the testing set were iteratively loaded and tested.  After iterating through the entire testing set, the average accuracy and a confusion matrix were computed as way to characterize the performance of the algorithm.  

"""

from __future__ import print_function
from __future__ import division
import numpy as np
import os
import sys
import nibabel as nib
import random
import pickle
import re
import json
import math

from nrximport import nrximport
pynrx = nrximport('pynrx', '1.0', verbose=True)
from pynrx.nrxfile.minc import Image

from keras.models import model_from_json
from keras import backend as K
from keras.models import Model

from keras.optimizers import SGD
from scipy import stats
import itertools


def get_files(fn):
    # fn is filename
    with open(fn) as f:
        # files are loaded as tuples with modality and filename
        files = [tuple(i.split(' ')) for i in f]
    return files


def test_DNN(test_files,NN,nb_mods,input_size):
    # this function loads the neural network architecture, the saved
    # weights from the training session and iteratively tests each f
    # in the list of test_files and keeps track of performance by modality

    # the model was defined and saved in modality.save_NNarch_toJson.py
    model = get_model(NN,nb_mods,verbose=False)
    # function to approximate output CNN based on model and estimated weights
    CNN_func = get_CNN_func()
    # weights filename identified and loaded into model
    weights_fn = './weights/weights.{0}.{1}mod.h5',format(NN,nb_mods)
    model.load_weights(weights_fn)
    # all possible modalities, if nb_mods=5, the first five are chosen
    modalities_all = ['flr','pdw','t1c','t1p','t2w','t1g','mtON','mtOFF']

    # confusion matrix to be populated while iterating through the files
    confusion_matrix = np.zeros((nb_mods,nb_mods))
    # number of slices to use from each MRI volume
    nb_slices = 30

    # iterate through all test_files
    for l,line in enumerate(test_files):
        # target modality categorized as a number and read from file
        mod_target = int(line[0])
        # filename read from files
        f = line[1].strip()
        # make some checks on the data and file name to ensure we are analyzing the correct file
        if (mod_target<nb_mods) and (modalities_all[mod_target] in f) and f.endswith(".mnc.gz"):
            try:
                # X is the output of the CNN as generated by input f that extracts the data, X has size: (1, nb_slices*nb_mods)
                X = gen_final_layer(f,CNN_func,nb_slices,nb_mods).reshape((1,nb_slices*nb_mods))
                batch_size = 32
                # probability is a vector of size (1,nb_mods) quantifying the probability f is each modality
                probability = model.predict(X,batch_size=32, verbose=0)
                # inferred modality categorized as a number from prediction generated by model output
                mod_infer=np.argmax(probability)
                

                status = "WRONG"
                if mod_infer == mod_target:
                    status = "CORRECT"
                # populate the confusion matrix by adding a single value in the correct place
                confusion_matrix[mod_infer,mod_target] += 1
                # count of the true positive by modality
                tp_mod=confusion_matrix.diagonal()
                # count of the total true positive
                tp_total = np.sum(mod_tp)
                # count of the files analyzed by modality
                count_mod=np.sum(confusion_matrix,0)
                # count of all the files analyzed
                count_total = np.sum(count_mod)
                
                print(f)
                print("{0} - [Target, Inferred, Probability]: [{1}, {2}, {3:0.4f}]".format(status, mod_target, modalities_all[mod_infer], probability[mod_infer]))
                print("Running Total Accuracy : [{0} of {1} = {2:0.2f} %] ".format(tp_total,count_total,tp_total * 100.0 / float(count_total)))
                print("Running Modality Accuracy : [{0} of {1} = {2:0.2f} %] ".format(tp_mod[mod_target],count_mod[mod_target],tp_mod[mod_target] * 100.0 / float(count_mod[mod_target])))
                print("")
            except Exception, e:
                print(f)
                print(str(e))
                print("Something did not work in the try section...")
                # sys.exit()
                pass

    np.set_printoptions(suppress=True)
    print("\nThe confusion matrix is:")
    print(modalities_all)
    print(confusion_matrix)

    
def get_model(NN='DNN',nb_mods=5,verbose=False):
    # load the architecture defined and saved in modality.save_NNarch_toJson.py
    fn = "./model/{0}_{1}mod.json".format(NN,nb_mods)
    # the model architecture is loaded from a .json f 
    with open(fn) as json_data:
        d = json.load(json_data)
    model = model_from_json(d)
    # compile the model architecture to ensure the dimensions match and are correct
    model.compile(loss='categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])
    # print to screen the model architecture, if desired by user
    if verbose:
        print(model.summary())
    return model


def get_CNN_func(nb_mods=5):
    # CNN_func is a function that estimates the CNN model with the loaded weights
    # given a sagittal slice as input CNN_func generates the same output as CNN

    # get the CNN model architecture
    NN='CNN'
    model=get_model(NN,nb_mods)
    # load the weights saved after training the CNN model
    weights_fn = './weights/weights.{0}.{1}mod.h5'.format(NN,nb_mods)
    model.load_weights(weights_fn)
    # select the final layer by name, edit to generate the output of another layer
    layer_name = 'soft_026'
    CNN_func = Model(inputs=model.input,outputs=model.get_layer(layer_name).output)

    return CNN_func


def gen_final_layer(img_fn,CNN_func,nb_slices,nb_mods=5):

    # load file as a numpy array using nibabel
    img = nib.load(img_fn).get_data()
    # reorder and invert axes
    img = np.swapaxes(img,0,2)
    img = img[::-1, ::-1, :]

    # in case the volume does not have enough sagittal slices
    if nb_slices>img.shape[0]:
        nb_slices=img.shape[0]

    # input to CNN in order to pass into CNN_func and generate CNN_out
    X_nb_slices = get_img_data(img,nb_slices)
    CNN_out=np.zeros((1,nb_slices,nb_mods))

    # populate CNN_out with prediction from CNN_func on each slice
    for n in range(nb_slices):
        layer_out = CNN_func.predict(X_nb_slices[n])
        CNN_out[0,n,:]= layer_out[0,:]
    return CNN_out


def get_img_data(img,nb_slices=30):
    # Get image data and normalize
    img = np.array(img).astype('float32')
    img = grab_sagittal(img,nb_slices)
    img = reshape_dimension(img)
    return img


def grab_sagittal(img,nb_slices):
    # extract sagittal nb_slices from img and preprocess
    # total number of sagittal slices in the MRI volume
    x_total = img.shape[0]
    # middle of the volume in the sagittal direction
    x_mid = np.around(x_total / 2).astype(int)
    # sagittal_volume is a list to populate in for loop and returned as numpy array
    sagittal_volume=[]
    # window is nb_slices divided by 2
    window = np.round(nb_slices / 2).astype(int)
    for x_idx in range(x_mid-window,x_mid+window):
        # sagittal slice extraced from img
        slice_sagittal=img[x_idx,:,:]
        # resample the sagittal slice to 32x32
        slice_resampled=resample_slice(slice_sagittal)
        # intensity normalize each slice
        slice_normalized=normalize(slice_resampled)
        # append to volume slice by slice
        sagittal_volume.append(slice_normalized)
    # return as a numpy array
    return np.asarray(sagittal_volume)


def resample_slice(dSlice):
    # size of the slice
    (Ny,Nz)=dSlice.shape
    # resample each slice to make it 32x32
    s=np.linspace(0,31,32)/32
    # sample in the y-direction
    sy=np.around(s*Ny).astype(int)
    tmp=dSlice[sy,:]
    # sample in the z-direction
    sz=np.around(s*Nz).astype(int)
    return tmp[:,sz]


def normalize(slice_array):
    # slice_array is intensity normalized by mean and variance
    # mean of the slice
    m=np.mean(slice_array)
    # standard deviation of the slice_array
    st=np.std(slice_array)
    slice_normalized = (slice_array - m) / st
    return slice_normalized


def reshape_dimension(img):
    # reorder the dimensions for the neural network architecture
    (x,y,z)=img.shape
    return np.reshape(img,(x,1,y,z))


# the entire dataset was split into three groups:
# train: list of files used for training the algorithm
# valid: list of files used for validation after each training epoch
# test : list of files used for testing the algorithm after training

# this code uses the files located in testing groups

test_fn = './cross_valid_fns/test.filenames.txt'
test_files = get_files(test_fn)

# select the dense neural network (DNN)
NN='DNN'
# number of modalities: [5,8] can be altered
nb_mods=5
# the dimension of one sagittal slice
input_size=(1,32,32)
# the size for the testing dataset
test_size=len(test_files)
# filename to save the output generate by the script
out_fn='./outdir/test_{0}_{1}mod_sz{2:05d}.log'.format(NN,nb_mods,test_size)
# open and write to filename identified in the line above
sys.stdout = open(out_fn,'w')
# print to the screen information regarding the testing session
print('\n==Testing {0}, number of modalities:{1} test_sz:{2} ==\n'.format(NN,nb_mods,test_sz))
# execute testing command
test_DNN(test_files,NN,nb_mods,input_size)

